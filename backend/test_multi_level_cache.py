"""æµ‹è¯•å¤šçº§ç¼“å­˜å’Œç¼“å­˜é¢„çƒ­åŠŸèƒ½"""

import asyncio
import time
from typing import Optional, Dict, Any


async def test_lru_cache():
    """æµ‹è¯• LRU ç¼“å­˜"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• LRU ç¼“å­˜")
    print("=" * 60)
    
    try:
        from app.cache.lru_cache import LRUCache
        
        # åˆ›å»º LRU ç¼“å­˜
        lru_cache = LRUCache(max_size=5, ttl=10)
        
        # æµ‹è¯•è®¾ç½®å’Œè·å–
        print("æµ‹è¯•åŸºæœ¬æ“ä½œ...")
        lru_cache.set("key1", "value1")
        lru_cache.set("key2", "value2")
        lru_cache.set("key3", "value3")
        
        assert lru_cache.get("key1") == "value1", "è·å– key1 å¤±è´¥"
        assert lru_cache.get("key2") == "value2", "è·å– key2 å¤±è´¥"
        assert lru_cache.get("key3") == "value3", "è·å– key3 å¤±è´¥"
        print("âœ… åŸºæœ¬æ“ä½œæµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯• LRU æ·˜æ±°
        print("\næµ‹è¯• LRU æ·˜æ±°...")
        lru_cache.set("key4", "value4")
        lru_cache.set("key5", "value5")
        lru_cache.set("key6", "value6")  # åº”è¯¥æ·˜æ±° key1
        
        assert lru_cache.get("key1") is None, "key1 åº”è¯¥è¢«æ·˜æ±°"
        assert lru_cache.get("key6") == "value6", "è·å– key6 å¤±è´¥"
        print("âœ… LRU æ·˜æ±°æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯• TTL è¿‡æœŸ
        print("\næµ‹è¯• TTL è¿‡æœŸ...")
        lru_cache.set("temp_key", "temp_value", ttl=1)
        assert lru_cache.get("temp_key") == "temp_value", "è·å– temp_key å¤±è´¥"
        time.sleep(2)
        assert lru_cache.get("temp_key") is None, "temp_key åº”è¯¥è¿‡æœŸ"
        print("âœ… TTL è¿‡æœŸæµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯
        print("\næµ‹è¯•ç»Ÿè®¡ä¿¡æ¯...")
        stats = lru_cache.get_stats()
        print(f"   ç¼“å­˜ç»Ÿè®¡: {stats}")
        assert stats["size"] > 0, "ç¼“å­˜å¤§å°åº”è¯¥å¤§äº 0"
        assert stats["max_size"] == 5, "æœ€å¤§ç¼“å­˜å¤§å°åº”è¯¥æ˜¯ 5"
        print("âœ… ç»Ÿè®¡ä¿¡æ¯æµ‹è¯•é€šè¿‡")
        
        print("\nâœ… LRU ç¼“å­˜æµ‹è¯•å…¨éƒ¨é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"\nâŒ LRU ç¼“å­˜æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


async def test_multi_level_cache():
    """æµ‹è¯•å¤šçº§ç¼“å­˜"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•å¤šçº§ç¼“å­˜")
    print("=" * 60)
    
    try:
        from app.cache.lru_cache import MultiLevelCache, LRUCache
        
        # åˆ›å»ºå¤šçº§ç¼“å­˜
        multi_cache = MultiLevelCache(l1_max_size=10, l1_ttl=300)
        
        # åˆ›å»ºæ¨¡æ‹Ÿçš„ L2 ç¼“å­˜
        class MockL2Cache:
            def __init__(self):
                self.cache = {}
            
            def get(self, key):
                return self.cache.get(key)
            
            def set(self, key, value, ttl=None):
                self.cache[key] = value
                return True
            
            def delete(self, key):
                if key in self.cache:
                    del self.cache[key]
                    return True
                return False
            
            def clear(self):
                self.cache.clear()
            
            def get_stats(self):
                return {"size": len(self.cache)}
        
        l2_cache = MockL2Cache()
        multi_cache.set_l2_cache(l2_cache)
        
        # æµ‹è¯• L1 ç¼“å­˜å‘½ä¸­
        print("æµ‹è¯• L1 ç¼“å­˜å‘½ä¸­...")
        multi_cache.set("key1", "value1")
        value = multi_cache.get("key1")
        assert value == "value1", "L1 ç¼“å­˜è·å–å¤±è´¥"
        print("âœ… L1 ç¼“å­˜å‘½ä¸­æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯• L2 ç¼“å­˜å‘½ä¸­
        print("\næµ‹è¯• L2 ç¼“å­˜å‘½ä¸­...")
        multi_cache.l1_cache.clear()  # æ¸…ç©º L1 ç¼“å­˜
        value = multi_cache.get("key1")
        assert value == "value1", "L2 ç¼“å­˜è·å–å¤±è´¥"
        # æ£€æŸ¥æ˜¯å¦å›å¡«åˆ° L1
        assert multi_cache.l1_cache.get("key1") == "value1", "åº”è¯¥å›å¡«åˆ° L1 ç¼“å­˜"
        print("âœ… L2 ç¼“å­˜å‘½ä¸­æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯• L3 æ•°æ®è·å–
        print("\næµ‹è¯• L3 æ•°æ®è·å–...")
        def fetcher(key):
            return f"fetched_{key}"
        
        multi_cache.set_l3_fetcher(fetcher)
        multi_cache.l1_cache.clear()
        l2_cache.cache.clear()
        
        value = multi_cache.get("key2")
        assert value == "fetched_key2", "L3 æ•°æ®è·å–å¤±è´¥"
        # æ£€æŸ¥æ˜¯å¦ç¼“å­˜åˆ° L1 å’Œ L2
        assert multi_cache.l1_cache.get("key2") == "fetched_key2", "åº”è¯¥ç¼“å­˜åˆ° L1"
        assert l2_cache.get("key2") == "fetched_key2", "åº”è¯¥ç¼“å­˜åˆ° L2"
        print("âœ… L3 æ•°æ®è·å–æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•ç¼“å­˜é¢„çƒ­
        print("\næµ‹è¯•ç¼“å­˜é¢„çƒ­...")
        multi_cache.l1_cache.clear()
        l2_cache.cache.clear()
        
        keys = ["key3", "key4", "key5"]
        count = multi_cache.warm_up(keys, fetcher)
        assert count == 3, f"åº”è¯¥é¢„çƒ­ 3 ä¸ªé”®ï¼Œå®é™…é¢„çƒ­äº† {count} ä¸ª"
        
        # éªŒè¯ç¼“å­˜
        for key in keys:
            assert multi_cache.l1_cache.get(key) == f"fetched_{key}", f"{key} åº”è¯¥åœ¨ L1 ç¼“å­˜ä¸­"
            assert l2_cache.get(key) == f"fetched_{key}", f"{key} åº”è¯¥åœ¨ L2 ç¼“å­˜ä¸­"
        print("âœ… ç¼“å­˜é¢„çƒ­æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•å¤šçº§ç¼“å­˜ç»Ÿè®¡
        print("\næµ‹è¯•å¤šçº§ç¼“å­˜ç»Ÿè®¡...")
        stats = multi_cache.get_stats()
        print(f"   å¤šçº§ç¼“å­˜ç»Ÿè®¡: {stats}")
        assert "l1" in stats, "åº”è¯¥åŒ…å« L1 ç»Ÿè®¡"
        assert "l2" in stats, "åº”è¯¥åŒ…å« L2 ç»Ÿè®¡"
        print("âœ… å¤šçº§ç¼“å­˜ç»Ÿè®¡æµ‹è¯•é€šè¿‡")
        
        print("\nâœ… å¤šçº§ç¼“å­˜æµ‹è¯•å…¨éƒ¨é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"\nâŒ å¤šçº§ç¼“å­˜æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


async def test_poi_cache_multi_level():
    """æµ‹è¯• POI å¤šçº§ç¼“å­˜"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• POI å¤šçº§ç¼“å­˜")
    print("=" * 60)
    
    try:
        from app.cache import get_poi_cache
        from app.models.schemas import POIInfo
        
        poi_cache = get_poi_cache()
        
        # æµ‹è¯•å¤šçº§ç¼“å­˜è®¾ç½®å’Œè·å–
        print("æµ‹è¯•å¤šçº§ç¼“å­˜è®¾ç½®å’Œè·å–...")
        pois = [
            POIInfo(id="1", name="æµ‹è¯•æ™¯ç‚¹1", type="æ™¯ç‚¹", address="æµ‹è¯•åœ°å€1", location={"longitude": 116.40, "latitude": 39.90}),
            POIInfo(id="2", name="æµ‹è¯•æ™¯ç‚¹2", type="æ™¯ç‚¹", address="æµ‹è¯•åœ°å€2", location={"longitude": 116.41, "latitude": 39.91})
        ]
        
        poi_cache.set("åŒ—äº¬", "æ•…å®«", True, pois)
        cached_pois = poi_cache.get("åŒ—äº¬", "æ•…å®«", True)
        
        assert cached_pois is not None, "ç¼“å­˜è·å–å¤±è´¥"
        assert len(cached_pois) == 2, f"åº”è¯¥æœ‰ 2 ä¸ª POIï¼Œå®é™…æœ‰ {len(cached_pois)} ä¸ª"
        print("âœ… å¤šçº§ç¼“å­˜è®¾ç½®å’Œè·å–æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•ç¼“å­˜ä¿¡æ¯
        print("\næµ‹è¯•ç¼“å­˜ä¿¡æ¯...")
        cache_info = poi_cache.get_cache_info("åŒ—äº¬", "æ•…å®«", True)
        print(f"   ç¼“å­˜ä¿¡æ¯: {cache_info}")
        assert "l1_exists" in cache_info, "åº”è¯¥åŒ…å« L1 å­˜åœ¨ä¿¡æ¯"
        assert "l2_exists" in cache_info, "åº”è¯¥åŒ…å« L2 å­˜åœ¨ä¿¡æ¯"
        print("âœ… ç¼“å­˜ä¿¡æ¯æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯
        print("\næµ‹è¯•ç»Ÿè®¡ä¿¡æ¯...")
        stats = poi_cache.get_stats()
        print(f"   POI ç¼“å­˜ç»Ÿè®¡: {stats}")
        assert "multi_level_stats" in stats, "åº”è¯¥åŒ…å«å¤šçº§ç¼“å­˜ç»Ÿè®¡"
        print("âœ… ç»Ÿè®¡ä¿¡æ¯æµ‹è¯•é€šè¿‡")
        
        print("\nâœ… POI å¤šçº§ç¼“å­˜æµ‹è¯•å…¨éƒ¨é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"\nâŒ POI å¤šçº§ç¼“å­˜æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


async def test_weather_cache_multi_level():
    """æµ‹è¯•å¤©æ°”å¤šçº§ç¼“å­˜"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•å¤©æ°”å¤šçº§ç¼“å­˜")
    print("=" * 60)
    
    try:
        from app.cache import get_weather_cache
        
        weather_cache = get_weather_cache()
        
        # æµ‹è¯•å¤šçº§ç¼“å­˜è®¾ç½®å’Œè·å–
        print("æµ‹è¯•å¤šçº§ç¼“å­˜è®¾ç½®å’Œè·å–...")
        weather_data = {
            "city": "åŒ—äº¬",
            "temperature": "25Â°C",
            "weather": "æ™´",
            "humidity": "60%"
        }
        
        weather_cache.set("åŒ—äº¬", weather_data)
        cached_weather = weather_cache.get("åŒ—äº¬")
        
        assert cached_weather is not None, "ç¼“å­˜è·å–å¤±è´¥"
        assert cached_weather["city"] == "åŒ—äº¬", "åŸå¸‚åº”è¯¥åŒ¹é…"
        print("âœ… å¤šçº§ç¼“å­˜è®¾ç½®å’Œè·å–æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•ç¼“å­˜ä¿¡æ¯
        print("\næµ‹è¯•ç¼“å­˜ä¿¡æ¯...")
        cache_info = weather_cache.get_cache_info("åŒ—äº¬")
        print(f"   ç¼“å­˜ä¿¡æ¯: {cache_info}")
        assert "l1_exists" in cache_info, "åº”è¯¥åŒ…å« L1 å­˜åœ¨ä¿¡æ¯"
        assert "l2_exists" in cache_info, "åº”è¯¥åŒ…å« L2 å­˜åœ¨ä¿¡æ¯"
        print("âœ… ç¼“å­˜ä¿¡æ¯æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯
        print("\næµ‹è¯•ç»Ÿè®¡ä¿¡æ¯...")
        stats = weather_cache.get_stats()
        print(f"   å¤©æ°”ç¼“å­˜ç»Ÿè®¡: {stats}")
        assert "multi_level_stats" in stats, "åº”è¯¥åŒ…å«å¤šçº§ç¼“å­˜ç»Ÿè®¡"
        print("âœ… ç»Ÿè®¡ä¿¡æ¯æµ‹è¯•é€šè¿‡")
        
        print("\nâœ… å¤©æ°”å¤šçº§ç¼“å­˜æµ‹è¯•å…¨éƒ¨é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"\nâŒ å¤©æ°”å¤šçº§ç¼“å­˜æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


async def test_llm_cache_multi_level():
    """æµ‹è¯• LLM å¤šçº§ç¼“å­˜"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• LLM å¤šçº§ç¼“å­˜")
    print("=" * 60)
    
    try:
        from app.cache import get_llm_cache
        
        llm_cache = get_llm_cache()
        
        # æµ‹è¯•å¤šçº§ç¼“å­˜è®¾ç½®å’Œè·å–
        print("æµ‹è¯•å¤šçº§ç¼“å­˜è®¾ç½®å’Œè·å–...")
        prompt = "åŒ—äº¬æœ‰å“ªäº›è‘—åçš„æ—…æ¸¸æ™¯ç‚¹ï¼Ÿ"
        response = "åŒ—äº¬æœ‰è®¸å¤šè‘—åçš„æ—…æ¸¸æ™¯ç‚¹ï¼ŒåŒ…æ‹¬æ•…å®«ã€å¤©å®‰é—¨å¹¿åœºã€é•¿åŸç­‰ã€‚"
        model = "deepseek-chat"
        
        llm_cache.set(prompt, response, model, 0.7)
        cached_response = llm_cache.get(prompt, model, 0.7)
        
        assert cached_response is not None, "ç¼“å­˜è·å–å¤±è´¥"
        assert cached_response["response"] == response, "å“åº”åº”è¯¥åŒ¹é…"
        print("âœ… å¤šçº§ç¼“å­˜è®¾ç½®å’Œè·å–æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•ç¼“å­˜ä¿¡æ¯
        print("\næµ‹è¯•ç¼“å­˜ä¿¡æ¯...")
        cache_info = llm_cache.get_cache_info(prompt, model, 0.7)
        print(f"   ç¼“å­˜ä¿¡æ¯: {cache_info}")
        assert "l1_exists" in cache_info, "åº”è¯¥åŒ…å« L1 å­˜åœ¨ä¿¡æ¯"
        assert "l2_exists" in cache_info, "åº”è¯¥åŒ…å« L2 å­˜åœ¨ä¿¡æ¯"
        print("âœ… ç¼“å­˜ä¿¡æ¯æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯
        print("\næµ‹è¯•ç»Ÿè®¡ä¿¡æ¯...")
        stats = llm_cache.get_stats()
        print(f"   LLM ç¼“å­˜ç»Ÿè®¡: {stats}")
        assert "multi_level_stats" in stats, "åº”è¯¥åŒ…å«å¤šçº§ç¼“å­˜ç»Ÿè®¡"
        print("âœ… ç»Ÿè®¡ä¿¡æ¯æµ‹è¯•é€šè¿‡")
        
        print("\nâœ… LLM å¤šçº§ç¼“å­˜æµ‹è¯•å…¨éƒ¨é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"\nâŒ LLM å¤šçº§ç¼“å­˜æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


async def test_cache_warmup():
    """æµ‹è¯•ç¼“å­˜é¢„çƒ­"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•ç¼“å­˜é¢„çƒ­")
    print("=" * 60)
    
    try:
        from app.cache.cache_warmup import get_warmup_manager, DEFAULT_POI_QUERIES
        
        warmup_manager = get_warmup_manager()
        
        # æµ‹è¯•è·å–é¢„çƒ­ç»Ÿè®¡
        print("æµ‹è¯•è·å–é¢„çƒ­ç»Ÿè®¡...")
        stats = warmup_manager.get_warmup_stats()
        print(f"   é¢„çƒ­ç»Ÿè®¡: {stats}")
        assert "poi_cache" in stats, "åº”è¯¥åŒ…å« POI ç¼“å­˜ç»Ÿè®¡"
        assert "weather_cache" in stats, "åº”è¯¥åŒ…å«å¤©æ°”ç¼“å­˜ç»Ÿè®¡"
        assert "llm_cache" in stats, "åº”è¯¥åŒ…å« LLM ç¼“å­˜ç»Ÿè®¡"
        print("âœ… é¢„çƒ­ç»Ÿè®¡æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•é»˜è®¤é¢„çƒ­æ•°æ®
        print("\næµ‹è¯•é»˜è®¤é¢„çƒ­æ•°æ®...")
        print(f"   é»˜è®¤ POI æŸ¥è¯¢æ•°é‡: {len(DEFAULT_POI_QUERIES)}")
        assert len(DEFAULT_POI_QUERIES) > 0, "åº”è¯¥æœ‰é»˜è®¤çš„ POI æŸ¥è¯¢"
        print("âœ… é»˜è®¤é¢„çƒ­æ•°æ®æµ‹è¯•é€šè¿‡")
        
        print("\nâœ… ç¼“å­˜é¢„çƒ­æµ‹è¯•å…¨éƒ¨é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"\nâŒ ç¼“å­˜é¢„çƒ­æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


async def test_cache_configuration():
    """æµ‹è¯•ç¼“å­˜é…ç½®"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•ç¼“å­˜é…ç½®")
    print("=" * 60)
    
    try:
        from app.config import get_settings
        
        settings = get_settings()
        
        # æµ‹è¯• L1 ç¼“å­˜é…ç½®
        print("æµ‹è¯• L1 ç¼“å­˜é…ç½®...")
        assert hasattr(settings, 'cache_poi_l1_max_size'), "åº”è¯¥æœ‰ POI L1 æœ€å¤§ç¼“å­˜å¤§å°é…ç½®"
        assert hasattr(settings, 'cache_poi_l1_ttl'), "åº”è¯¥æœ‰ POI L1 TTL é…ç½®"
        assert hasattr(settings, 'cache_weather_l1_max_size'), "åº”è¯¥æœ‰å¤©æ°” L1 æœ€å¤§ç¼“å­˜å¤§å°é…ç½®"
        assert hasattr(settings, 'cache_weather_l1_ttl'), "åº”è¯¥æœ‰å¤©æ°” L1 TTL é…ç½®"
        assert hasattr(settings, 'cache_llm_l1_max_size'), "åº”è¯¥æœ‰ LLM L1 æœ€å¤§ç¼“å­˜å¤§å°é…ç½®"
        assert hasattr(settings, 'cache_llm_l1_ttl'), "åº”è¯¥æœ‰ LLM L1 TTL é…ç½®"
        
        print(f"   POI L1 ç¼“å­˜: max_size={settings.cache_poi_l1_max_size}, ttl={settings.cache_poi_l1_ttl}s")
        print(f"   å¤©æ°” L1 ç¼“å­˜: max_size={settings.cache_weather_l1_max_size}, ttl={settings.cache_weather_l1_ttl}s")
        print(f"   LLM L1 ç¼“å­˜: max_size={settings.cache_llm_l1_max_size}, ttl={settings.cache_llm_l1_ttl}s")
        print("âœ… L1 ç¼“å­˜é…ç½®æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯• L2 ç¼“å­˜é…ç½®
        print("\næµ‹è¯• L2 ç¼“å­˜é…ç½®...")
        assert hasattr(settings, 'cache_poi_ttl'), "åº”è¯¥æœ‰ POI L2 TTL é…ç½®"
        assert hasattr(settings, 'cache_weather_ttl'), "åº”è¯¥æœ‰å¤©æ°” L2 TTL é…ç½®"
        assert hasattr(settings, 'cache_llm_ttl'), "åº”è¯¥æœ‰ LLM L2 TTL é…ç½®"
        
        print(f"   POI L2 ç¼“å­˜: ttl={settings.cache_poi_ttl}s")
        print(f"   å¤©æ°” L2 ç¼“å­˜: ttl={settings.cache_weather_ttl}s")
        print(f"   LLM L2 ç¼“å­˜: ttl={settings.cache_llm_ttl}s")
        print("âœ… L2 ç¼“å­˜é…ç½®æµ‹è¯•é€šè¿‡")
        
        print("\nâœ… ç¼“å­˜é…ç½®æµ‹è¯•å…¨éƒ¨é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"\nâŒ ç¼“å­˜é…ç½®æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n" + "=" * 60)
    print("å¼€å§‹æµ‹è¯•å¤šçº§ç¼“å­˜å’Œç¼“å­˜é¢„çƒ­åŠŸèƒ½")
    print("=" * 60)
    
    results = {}
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    results["LRU ç¼“å­˜"] = await test_lru_cache()
    results["å¤šçº§ç¼“å­˜"] = await test_multi_level_cache()
    results["POI å¤šçº§ç¼“å­˜"] = await test_poi_cache_multi_level()
    results["å¤©æ°”å¤šçº§ç¼“å­˜"] = await test_weather_cache_multi_level()
    results["LLM å¤šçº§ç¼“å­˜"] = await test_llm_cache_multi_level()
    results["ç¼“å­˜é¢„çƒ­"] = await test_cache_warmup()
    results["ç¼“å­˜é…ç½®"] = await test_cache_configuration()
    
    # æ‰“å°æµ‹è¯•ç»“æœ
    print("\n" + "=" * 60)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)
    
    for test_name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")
    
    total_tests = len(results)
    passed_tests = sum(1 for r in results.values() if r)
    
    print(f"\næ€»è®¡: {passed_tests}/{total_tests} æµ‹è¯•é€šè¿‡")
    
    if passed_tests == total_tests:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        print(f"\nâš ï¸  {total_tests - passed_tests} ä¸ªæµ‹è¯•å¤±è´¥")
    
    return passed_tests == total_tests


if __name__ == "__main__":
    success = asyncio.run(main())
    exit(0 if success else 1)
